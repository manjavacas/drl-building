\chapter*{}

\input{portada/portada_2}

\cleardoublepage
\thispagestyle{empty}

\begin{center}
{\large\bfseries Deep Reinforcement Learning para control energético eficiente de edificios}\\
\end{center}
\begin{center}
Antonio Manjavacas Lucas\\
\end{center}

\noindent{\textbf{Palabras clave}: Aprendizaje profundo por refuerzo; Control energético de edificios; Agentes inteligentes}\\

\vspace{0.7cm}
\noindent{\textbf{Resumen}}\\

En las últimas décadas, tanto el calentamiento global como el cambio climático se han visto significativamente afectados por el incremento de la demanda energética de edificios residenciales y comerciales. Estos son responsables de un tercio del consumo mundial de energía y de hasta un 40\% de las emisiones de CO$_2$, mayormente producidas por los sistemas de calefacción, ventilación y aire acondicionado (HVAC) destinados a garantizar el bienestar de sus ocupantes.

Ante esta problemática, optimizar el control de los sistemas HVAC se plantea como una solución necesaria ante el creciente interés por garantizar la eficiencia energética de los edificios. Dicho control ha sido tradicionalmente llevado a cabo mediante técnicas reactivas, las cuales no siempre garantizan la maximización del confort de los ocupantes y, al mismo tiempo, la minimización del consumo energético a largo plazo.

En contraposición a estos métodos tradicionales, en los últimos años ha aumentado el interés por las técnicas basadas en aprendizaje profundo por refuerzo (DRL) orientadas a control HVAC, a raíz de los resultados exitosos en otras áreas, como la robótica o los juegos. No obstante, se trata de un campo relativamente inmaduro, donde se carece de marcos de referencia y bancos de prueba específicamente destinados a reproducir y comparar los diferentes algoritmos que conforman el estado del arte.

En respuesta a esta necesidad, el objetivo perseguido en este trabajo será el desarrollo de un entorno de ejecución de simulaciones energéticas orientado al uso y evaluación de diferentes algoritmos de DRL en control HVAC. A su vez, se profundizará en la experimentación con estos algoritmos haciendo uso del entorno implementado, evaluando los resultados obtenidos en términos de consumo energético y confort.

\cleardoublepage
\thispagestyle{empty}

\begin{center}
{\large\bfseries Deep Reinforcement Learning for efficient building energy control}\\
\end{center}
\begin{center}
Antonio Manjavacas Lucas\\
\end{center}

\noindent{\textbf{Keywords}: Deep Reinforcement Learning; Building energy control; Intelligent agents}\\

\vspace{0.7cm}
\noindent{\textbf{Abstract}}\\

In recent decades, both global warming and climate change have been significantly affected by the increased energy demand of residential and commercial buildings. These are responsible for one third of global energy consumption and up to 40\% of CO$_2$ emissions, mostly produced by heating, ventilation and air conditioning (HVAC) systems designed to ensure the well-being of their occupants.

Given this problem, optimizing the control of HVAC systems is a necessary solution in view of the growing interest in guaranteeing the energy efficiency of buildings. This control has traditionally been carried out by means of reactive techniques, which do not always guarantee the maximization of occupants' comfort and, at the same time, the long-term minimization of energy consumption.

In contrast to these traditional methods, in recent years there has been a growing interest in deep reinforcement learning (DRL) techniques for HVAC control, following successful results in other areas such as robotics or games. However, this is a relatively immature field, where there is a lack of reference frameworks and benchmarks specifically aimed at reproducing and comparing the different algorithms that comprise the state of the art.

As a response to this need, the objective of this work will be the development of an environment for the execution of energy simulations oriented to the use and evaluation of different DRL algorithms in HVAC control. At the same time, the experimentation with these algorithms using the implemented environment will be deepened, evaluating the results obtained in terms of energy consumption and comfort.

\chapter*{}
\thispagestyle{empty}

Yo, \textbf{Antonio Manjavacas}, alumno de la titulación Máster Universitario Oficial en Ciencia de Datos e Ingeniería de Computadores de la \textbf{Escuela Técnica Superior
de Ingenierías Informática y de Telecomunicación de la Universidad de Granada}, con DNI \textbf{06286831B}, autorizo la ubicación de la siguiente copia de mi Trabajo Fin de Máster en la biblioteca del centro para que pueda ser
consultada por las personas que lo deseen.

\vspace{6cm}

\begin{center}
    \noindent Antonio Manjavacas Lucas
\end{center}

\vspace{2cm}

\begin{flushright}
Granada a \today .
\end{flushright}

\chapter*{}
\thispagestyle{empty}

D. \textbf{Juan Gómez Romero}, profesor titular del Departamento Ciencias de la Computación e Inteligencia Artificial de la Universidad de Granada.

\vspace{0.5cm}

D. \textbf{Miguel Molina Solana}, profesor ayudante doctor del Departamento Ciencias de la Computación e Inteligencia Artificial de la Universidad de Granada.

\vspace{0.5cm}

\textbf{Informan:}

\vspace{0.5cm}

Que el presente trabajo, titulado \textit{\textbf{Deep Reinforcement Learning para control energético eficiente de edificios}}, ha sido realizado bajo su supervisión por \textbf{Antonio Manjavacas Lucas}, y autorizan la defensa de dicho trabajo ante el tribunal que corresponda.

\vspace{0.5cm}

Y para que conste, expiden y firman el presente informe en Granada a \today.

\vspace{1cm}

\textbf{Los directores:}

\vspace{5cm}

\begin{center}
    \noindent \textbf{Juan Gómez Romero \ \ \ \ \ Miguel Molina Solana}
\end{center}

\chapter*{Agradecimientos}
\thispagestyle{empty}

\vspace{1cm}

Quisiera dar las gracias y dedicar este trabajo a todas las personas que, desde lo personal como lo profesional, me han acompañado a lo largo de este maravilloso año, repleto de aprendizaje y buenas experiencias.

Gracias a Juan y Miguel, por su cercanía y sus buenos consejos, así como por brindarme la oportunidad de colaborar en este proyecto y profundizar en mi pasión por el aprendizaje por refuerzo, un campo que me apasiona y del que nunca dejaré de aprender. 

Este trabajo tampoco habría sido posible sin la ayuda incondicional de Alejandro y Javier, compañeros de trabajo, reuniones, mensajes de Slack y satisfacciones por ver crecer esta iniciativa. En palabras de Javier: ``hace unos meses parecía algo muy lejano''. ¡Gracias por todo!

También quisiera agradecer a mis padres, Antonio y Criptana, todo su sacrificio y ánimo a lo largo de un año marcado por la distancia. Gracias por entender lo que me hace feliz y prestarme todo vuestro apoyo.

Gracias a Andrea, Ithiel, Patricio, Margarita y Anouk, compañeros a lo largo de un viaje que comenzó en diciembre y terminó en La Gomera. Seguro que volveremos a encontrarnos.

A mis buenos amigos \textit{granaínos} y no tan \textit{granaínos}: Carlos, Mape, Eva, Elena, Jose, Pablo, Juanje, Blanca... ¡sois muchos los que habéis hecho de este un año inigualable! Gracias, de corazón, por todos los buenos momentos y experiencias compartidas.

Por último, pero no menos importante, quisiera dar las gracias a Laura y Virginia. Jamás pensé que en un año marcado por la pandemia y la ``distancia social'' me acercaría tanto a dos personas tan maravillosas. Gracias por soportarme, ser testigos de mi trabajo y estar ahí en los buenos y malos momentos. 

\begin{flushright}
\textit{Antonio Manjavacas Lucas\\
Granada, 27 de junio de 2021}
\end{flushright}

